{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA EXTRACTION\n",
    "\n",
    "###  1. Move from xml to pandas dataframe\n",
    "\n",
    "The basic idea of this step is to have a neat tabular representation of the records in DBLP like <b> [ Key , Author , Title , Year ]</b>. In other words, we would need to transform the existing XML (tree based) representation (dblp.xml) into a .csv file (relational/tabular representation). \n",
    "\n",
    "To do so, we need to :\n",
    "\n",
    "   1. Parse the XML \n",
    "   2. Find necessary articles and information \n",
    "   3. Write to .csv file \n",
    "   4. Plot Extraction results\n",
    "   5. Clean the csv files\n",
    "   \n",
    "This notebook contains steps 1 to 4 step 5 will be the subject of the notebook 'DBLP_Cleaning'. Also, the plot is generated in a seperate notebook but just shown here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Parsing -- Formatting Issues\n",
    "\n",
    "It should normally be quite straightforward to parse a valid xml file using the ElementTree (ET) (part of the xml standard library in python).\n",
    "\n",
    "However, the first problem encountered was that the XML in the 'dblp.xml' is not parseable due to the presence of 'named entity' latin-1 encoding, it was meant to be in the 'numeric' latin-1 and thus creates parse errors. \n",
    "(<i>cf Section 2 of 'DBLP_Some_Lessons_Learned' (in the Documents folder)</i>)\n",
    "\n",
    "To overcome this, we extract the required mapping from the <i> Data Type Definition file (dblp.dtd) </i>, replace the strings accordingly and then use it to build the parse tree using ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dblp_dtd_dict = {\"&Agrave;\" : \"&#192;\",\"&Aacute;\" : \"&#193;\",\"&Acirc;\" : \"&#194;\",\"&Atilde;\" : \"&#195;\",\n",
    "                 \"&Auml;\" : \"&#196;\",\"&Aring;\" : \"&#197;\",\"&AElig;\" : \"&#198;\",\"&Ccedil;\" : \"&#199;\",\n",
    "                 \"&Egrave;\" : \"&#200;\",\"&Eacute;\" : \"&#201;\",\"&Ecirc;\" : \"&#202;\",\"&Euml;\" : \"&#203;\",\n",
    "                 \"&Igrave;\" : \"&#204;\",\"&Iacute;\" : \"&#205;\",\"&Icirc;\" : \"&#206;\",\"&Iuml;\" : \"&#207;\",\n",
    "                 \"&ETH;\" : \"&#208;\",\"&Ntilde;\" : \"&#209;\",\"&Ograve;\" : \"&#210;\",\"&Oacute;\" : \"&#211;\",\n",
    "                 \"&Ocirc;\" : \"&#212;\",\"&Otilde;\" : \"&#213;\",\"&Ouml;\" : \"&#214;\",\"&Oslash;\" : \"&#216;\",\n",
    "                 \"&Ugrave;\" : \"&#217;\",\"&Uacute;\" : \"&#218;\",\"&Ucirc;\" : \"&#219;\",\"&Uuml;\" : \"&#220;\",\n",
    "                 \"&Yacute;\" : \"&#221;\",\"&THORN;\" : \"&#222;\",\"&szlig;\" : \"&#223;\",\"&agrave;\" : \"&#224;\",\n",
    "                 \"&aacute;\" : \"&#225;\",\"&acirc;\" : \"&#226;\",\"&atilde;\" : \"&#227;\",\"&auml;\" : \"&#228;\",\n",
    "                 \"&aring;\" : \"&#229;\",\"&aelig;\" : \"&#230;\",\"&ccedil;\" : \"&#231;\",\"&egrave;\" : \"&#232;\",\n",
    "                 \"&eacute;\" : \"&#233;\",\"&ecirc;\" : \"&#234;\",\"&euml;\" : \"&#235;\",\"&igrave;\" : \"&#236;\",\n",
    "                 \"&iacute;\" : \"&#237;\",\"&icirc;\" : \"&#238;\",\"&iuml;\" : \"&#239;\",\"&eth;\" : \"&#240;\",\n",
    "                 \"&ntilde;\" : \"&#241;\",\"&ograve;\" : \"&#242;\",\"&oacute;\" : \"&#243;\",\"&ocirc;\" : \"&#244;\",\n",
    "                 \"&otilde;\" : \"&#245;\",\"&ouml;\" : \"&#246;\",\"&oslash;\" : \"&#248;\",\"&ugrave;\" : \"&#249;\",\n",
    "                 \"&uacute;\" : \"&#250;\",\"&ucirc;\" : \"&#251;\",\"&uuml;\" : \"&#252;\",\"&yacute;\" : \"&#253;\",\n",
    "                 \"&thorn;\" : \"&#254;\",\"&yuml;\" : \"&#255;\", \"&times;\": \"&#215;\", \"&micro;\" : \"&#181;\" ,\n",
    "                 \"&reg;\" :\"&#174;\"  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code replaces the special encoding and writes it to the file 'dblp_clean.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2087788233"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblp_text = open('dblp.xml', 'r').read()\n",
    "\n",
    "for key in dblp_dtd_dict.keys():\n",
    "    dblp_text = dblp_text.replace(key, dblp_dtd_dict[key])\n",
    "    \n",
    "dblp_clean = open('dblp_clean.xml', 'w')\n",
    "dblp_clean.write(dblp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Parsing --  XML  Element tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dblp_tree = ET.parse('dblp_clean.xml')\n",
    "dblp_root = dblp_tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Resource Types and Extraction to .csv\n",
    "\n",
    "There are many different types of resources in the XML tree. The ones that matter for the sake of this project are outlined as follows: \n",
    "\n",
    "\n",
    "   1. Articles : Contain articles published in either Journals or Books and Year\n",
    "   2. Books    : Contain books published, Year , publisher , isbn etc..\n",
    "   3. Theses   : Masters theses and Phd theses, contain author, title and university.\n",
    "   4. Persons  : Contain information about the authors, specially aliases they hold!\n",
    "   5. Proceedings : Information on Editors of conferences, titles , year etc \n",
    "   6. Inproceedings : Contain author, title, year and conference.\n",
    "   7. Incollections : Contain author, title and year.\n",
    "   \n",
    "For each record type in DBLP, there are a few that have no Author field, which is inconvenient for our project as we wish to make a recommender system based on Authors and Titles. The proportion retrieved among the ones that do have Author information is 100% for all record types. The unretrieved proportion is shown in the plot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journals/expert/AlonsoAAM97\n",
      "journals/expert/AlonsoAAM97\n",
      "journals/expert/AlonsoAAM97\n",
      "journals/expert/AlonsoAAM97\n"
     ]
    }
   ],
   "source": [
    "articles_w_authors  = len(dblp_root.findall('article'))\n",
    "\n",
    "with open('dblp_articles.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Article', 'Author', 'Title', 'Publication', 'Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for article in dblp_root.iter('article'):\n",
    "        if len(article.findall('author')) != 0:\n",
    "            for author in article.findall('author'):\n",
    "                try:\n",
    "                    publication = article.find('journal').text if article.find('journal') != None else article.find('booktitle').text\n",
    "    \n",
    "                    out.writerow({'Article': article.get('key'),\n",
    "                                  'Author': author.text,\n",
    "                                  'Title': ''.join(article.find('title').itertext()),\n",
    "                                  'Publication': publication,\n",
    "                                  'Year': article.find('year').text\n",
    "                             })\n",
    "                except:\n",
    "                    print(article.get('key'))\n",
    "        else:\n",
    "            articles_w_authors -= 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above output the only publication that is neither a book nor a journal has the following key: <b><i>journals/expert/AlonsoAAM97</i></b>.\n",
    "\n",
    "Luckily, in the Documentation folder, we have a paper on how to request the record using the key. (<i>DBLP_XML_Requests</i>) here we check why this one record is misbehaving\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"US-ASCII\"?>\n",
      "<dblp>\n",
      "<article key=\"journals/expert/AlonsoAAM97\" publtype=\"informal publication\" mdate=\"2016-12-15\">\n",
      "<author>Gustavo Alonso</author>\n",
      "<author>Divyakant Agrawal</author>\n",
      "<author>Amr El Abbadi</author>\n",
      "<author>C. Mohan 0001</author>\n",
      "<title>Functionality and Limitations of Current Workflow Management Systems.</title>\n",
      "<year>1997</year>\n",
      "<note>unpublished; submitted to IEEE Expert</note>\n",
      "<ee>http://www.almaden.ibm.com/cs/exotica/wfmsys.pdf</ee>\n",
      "</article>\n",
      "</dblp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requests.post('http://dblp.uni-trier.de/rec/xml/journals/expert/AlonsoAAM97').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, It was a paper that was unpublished at the time but submitted to IEEE Expert. therefore, we subtract this record from our 'articles_w_authors' counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n",
      "Proportion of articles with authors in DBLP: \n",
      "0.9945393108183805\n"
     ]
    }
   ],
   "source": [
    "n_retrieved = pd.read_csv('dblp_articles.csv').Article.nunique()\n",
    "\n",
    "print('Proportion retrieved : ')\n",
    "print(n_retrieved / (articles_w_authors-1))\n",
    "\n",
    "print('Proportion of articles with authors in DBLP: ')\n",
    "print(n_retrieved / len(dblp_root.findall('article')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2  Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books_w_authors = len(dblp_root.findall('book'))\n",
    "\n",
    "with open('dblp_books.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Book', 'Author', 'Title', 'Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    counter = 0\n",
    "    for book in dblp_root.iter('book'):\n",
    "        if len(book.findall('author')) != 0:\n",
    "            for author in book.findall('author'):\n",
    "                try:\n",
    "                    out.writerow({'Book': book.get('key'),\n",
    "                                  'Author': author.text,\n",
    "                                  'Title': ''.join(book.find('title').itertext()),\n",
    "                                  'Year': book.find('year').text\n",
    "                                })\n",
    "                except:\n",
    "                    print(book.get('key'))\n",
    "        else:\n",
    "            books_w_authors -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n",
      "Proportion of books with authors in DBLP: \n",
      "0.9089845748958257\n"
     ]
    }
   ],
   "source": [
    "n_retrieved = pd.read_csv('dblp_books.csv').Book.nunique()\n",
    "\n",
    "print('Proportion retrieved : ')\n",
    "print(n_retrieved/ books_w_authors)\n",
    "\n",
    "print('Proportion of books with authors in DBLP: ')\n",
    "print(n_retrieved / len(dblp_root.findall('book')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3  Theses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('dblp_theses.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Thesis', 'Author', 'Title', 'Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for thesis in dblp_root.iter('phdthesis'):\n",
    "        for author in thesis.findall('author'):\n",
    "            try:\n",
    "                out.writerow({'Thesis': thesis.get('key'),\n",
    "                            'Author': author.text,\n",
    "                            'Title': ''.join(thesis.find('title').itertext()),\n",
    "                            'Year': thesis.find('year').text\n",
    "                            })\n",
    "            except:\n",
    "                print(thesis.get('key'))\n",
    "    \n",
    "    for thesis in dblp_root.iter('mastersthesis'):\n",
    "        for author in thesis.findall('author'):\n",
    "            try:\n",
    "                out.writerow({'Thesis': thesis.get('key'),\n",
    "                            'Author': author.text,\n",
    "                            'Title': ''.join(thesis.find('title').itertext()),\n",
    "                            'Year': thesis.find('year').text\n",
    "                            })\n",
    "            except:\n",
    "                print(thesis.get('key'))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_retrieved = pd.read_csv('dblp_theses.csv').Thesis.nunique()\n",
    "\n",
    "print('Proportion retrieved : ')\n",
    "print( n_retrieved/ (len(dblp_root.findall('phdthesis')) + len(dblp_root.findall('mastersthesis'))))\n",
    "\n",
    "print('Proportion of theses with authors in DBLP: ')\n",
    "print(n_retrieved / len(dblp_root.findall('mastersthesis')+len(dblp_root.findall('phdthesis')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'homepages' resources have what are called the Person Records (<i>cf Page 7 of 'DBLP_Some_Lessons_Learned'</i>). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_persons = len(dblp_root.findall('www'))\n",
    "\n",
    "with open('dblp_persons.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Resource', 'Author']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for resource in dblp_root.iter('www'):\n",
    "        if 'homepages' in resource.get('key'):\n",
    "            for author in resource.findall('author'):\n",
    "                try:\n",
    "                    out.writerow({'Resource': resource.get('key'),\n",
    "                                  'Author': author.text,\n",
    "                                })\n",
    "                except:\n",
    "                    print(resource.get('key'))\n",
    "        else:\n",
    "            n_persons -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999828689076904"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Proportion retrieved : ')\n",
    "pd.read_csv('dblp_persons.csv').Resource.nunique() / n_persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.3.5 Proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proceedings_w_editor = len(dblp_root.findall('proceedings'))\n",
    "\n",
    "with open('dblp_proceedings.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Proceeding', 'Editor', 'Title', 'Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for proceeding in dblp_root.iter('proceedings'):\n",
    "        if len(proceeding.findall('editor')) !=0 :\n",
    "            \n",
    "            for editor in proceeding.findall('editor'):\n",
    "                    try:\n",
    "                        out.writerow({'Proceeding': proceeding.get('key'),\n",
    "                                      'Editor': editor.text,\n",
    "                                      'Title' : ''.join(proceeding.find('title').itertext()),\n",
    "                                      'Year' : proceeding.find('year').text\n",
    "                                    })\n",
    "                    except:\n",
    "                        print(proceeding.get('key'))\n",
    "        else:\n",
    "            proceedings_w_editor -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n",
      "Proportion of proceedings with editors in DBLP: \n",
      "0.7727166070276295\n"
     ]
    }
   ],
   "source": [
    "n_retrieved = pd.read_csv('dblp_proceedings.csv').Proceeding.nunique()\n",
    "\n",
    "print('Proportion retrieved : ')\n",
    "print(n_retrieved/ proceedings_w_editor)\n",
    "\n",
    "print('Proportion of proceedings with editors in DBLP: ')\n",
    "print(n_retrieved / len(dblp_root.findall('proceedings')) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.6 Inproceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inproceedings_w_authors = len(dblp_root.findall('inproceedings'))\n",
    "\n",
    "with open('dblp_inproceedings.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Inproceedings', 'Author', 'Title', 'Publication','Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for article in dblp_root.iter('inproceedings'):\n",
    "        if len(article.findall('author'))!= 0:\n",
    "            for author in article.findall('author'):\n",
    "                try:\n",
    "                    publication = article.find('journal').text if article.find('journal') != None else article.find('booktitle').text\n",
    "                \n",
    "                    out.writerow({'Inproceedings': article.get('key'),\n",
    "                                  'Author': author.text,\n",
    "                                  'Title': ''.join(article.find('title').itertext()),\n",
    "                                  'Publication': publication,\n",
    "                                  'Year': article.find('year').text\n",
    "                                 })\n",
    "                except:\n",
    "                    print(article.get('key'))\n",
    "        else:\n",
    "            inproceedings_w_authors -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n",
      "Proportion of inproceedings with authors in DBLP: \n",
      "0.9985253170568328\n"
     ]
    }
   ],
   "source": [
    "print('Proportion retrieved : ')\n",
    "print(pd.read_csv('dblp_inproceedings.csv').Inproceedings.nunique()/inproceedings_w_authors)\n",
    "print('Proportion of inproceedings with authors in DBLP: ')\n",
    "print(pd.read_csv('dblp_inproceedings.csv').Inproceedings.nunique()/len(dblp_root.findall('inproceedings')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.7 Incollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_w_authors = len(dblp_root.findall('incollection'))\n",
    "\n",
    "with open('dblp_incollections.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    cols = ['Incollection', 'Author', 'Title', 'Publication','Year']\n",
    "    out = csv.DictWriter(csvfile, cols)\n",
    "    out.writeheader()\n",
    "    for article in dblp_root.iter('incollection'):\n",
    "        if len(article.findall('author'))!= 0:\n",
    "            for author in article.findall('author'):\n",
    "                try:            \n",
    "                    out.writerow({'Incollection': article.get('key'),\n",
    "                                  'Author': author.text,\n",
    "                                  'Title': ''.join(article.find('title').itertext()),\n",
    "                                  'Publication': article.find('booktitle').text,\n",
    "                                  'Year': article.find('year').text\n",
    "                                 })\n",
    "                except:\n",
    "                    print(article.get('key'))\n",
    "        else:\n",
    "            collection_w_authors -= 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion retrieved : \n",
      "1.0\n",
      "Proportion of incollections with authors in DBLP: \n",
      "0.790610599078341\n"
     ]
    }
   ],
   "source": [
    "print('Proportion retrieved : ')\n",
    "print(pd.read_csv('dblp_incollections.csv').Incollection.nunique()/collection_w_authors)\n",
    "\n",
    "print('Proportion of incollections with authors in DBLP: ')\n",
    "print(pd.read_csv('dblp_incollections.csv').Incollection.nunique()/len(dblp_root.findall('incollection')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.4 Extraction Results -- Plot \n",
    "\n",
    "![results](Plots/results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
